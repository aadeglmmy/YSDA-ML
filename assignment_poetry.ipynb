{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NhJ-ktFPkDG"
      },
      "source": [
        "### Генерация поэзии с помощью нейронных сетей: шаг 1\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), @neychev\n",
        "\n",
        "Ваша основная задача: научиться генерироват стихи с помощью простой рекуррентной нейронной сети (Vanilla RNN). В качестве корпуса текстов для обучения будет выступать роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0c6uaUaPkDI"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import string\n",
        "import os\n",
        "from random import sample\n",
        "\n",
        "import numpy as np\n",
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9_WoVkdPkDJ",
        "outputId": "b6d69e39-4df7-4cdf-8ad1-5b1249e82e6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda device is available\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print('{} device is available'.format(device))\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPenWOy01Ooa",
        "outputId": "a92e8e33-e009-4bd4-ac12-3b1b5e1cd3f2"
      },
      "source": [
        "#### 1. Загрузка данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nackSRIMPkDJ",
        "outputId": "264662af-829a-4498-ac80-ddcdfd53725b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-02 16:40:44--  https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/onegin.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 262521 (256K) [text/plain]\n",
            "Saving to: ‘onegin.txt’\n",
            "\n",
            "\ronegin.txt            0%[                    ]       0  --.-KB/s               \ronegin.txt          100%[===================>] 256.37K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-12-02 16:40:45 (8.35 MB/s) - ‘onegin.txt’ saved [262521/262521]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "!wget https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/onegin.txt\n",
        "\n",
        "with open('onegin.txt', 'r') as iofile:\n",
        "    text = iofile.readlines()\n",
        "\n",
        "text = \"\".join([x.replace('\\t\\t', '').lower() for x in text])\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQYpmGfR_gJ8"
      },
      "source": [
        "#### 2. Построение словаря и предобработка текста\n",
        "В данном задании требуется построить языковую модель на уровне символов. Приведем весь текст к нижнему регистру и построим словарь из всех символов в доступном корпусе текстов. Также добавим токен `<sos>`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Uru2i_0PkDK",
        "outputId": "e9383576-b396-4771-f47c-c9eb45e923ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "tokens = sorted(set(text.lower())) + ['<sos>']\n",
        "num_tokens = len(tokens)\n",
        "\n",
        "assert num_tokens == 84, \"Check the tokenization process\"\n",
        "\n",
        "token_to_idx = {x: idx for idx, x in enumerate(tokens)}\n",
        "idx_to_token = {idx: x for idx, x in enumerate(tokens)}\n",
        "\n",
        "assert len(tokens) == len(token_to_idx), \"Mapping should be unique\"\n",
        "\n",
        "print(\"Seems fine!\")\n",
        "\n",
        "\n",
        "text_encoded = [token_to_idx[x] for x in text]\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI-0HjxYPkDK"
      },
      "source": [
        "__Ваша задача__: обучить классическую рекуррентную нейронную сеть (Vanilla RNN) предсказывать следующий символ на полученном корпусе текстов и сгенерировать последовательность длины 100 для фиксированной начальной фразы.\n",
        "\n",
        "Вы можете воспользоваться кодом с занятие №6 или же обратиться к следующим ссылкам:\n",
        "* Замечательная статья за авторством Andrej Karpathy об использовании RNN: [link](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
        "* Пример char-rnn от Andrej Karpathy: [github repo](https://github.com/karpathy/char-rnn)\n",
        "* Замечательный пример генерации поэзии Шекспира: [github repo](https://github.com/spro/practical-pytorch/blob/master/char-rnn-generation/char-rnn-generation.ipynb)\n",
        "\n",
        "Данное задание является достаточно творческим. Не страшно, если поначалу оно вызывает затруднения. Последняя ссылка в списке выше может быть особенно полезна в данном случае.\n",
        "\n",
        "Далее для вашего удобства реализована функция, которая генерирует случайный батч размера `batch_size` из строк длиной `seq_length`. Вы можете использовать его при обучении модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Zpt5PiwPkDL"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "batch_size = 256\n",
        "seq_length = 100\n",
        "start_column = np.zeros((batch_size, 1), dtype=int) + token_to_idx['<sos>']\n",
        "\n",
        "def generate_chunk():\n",
        "    global text_encoded, start_column, batch_size, seq_length\n",
        "\n",
        "    start_index = np.random.randint(0, len(text_encoded) - batch_size*seq_length - 1)\n",
        "    data = np.array(text_encoded[start_index:start_index + batch_size*seq_length]).reshape((batch_size, -1))\n",
        "    yield np.hstack((start_column, data))\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7zK1IYWPkDL"
      },
      "source": [
        "Пример батча:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLMBstiUPkDL",
        "outputId": "54fcff36-1278-4e63-8b8d-98b42c7ef7d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[83, 53, 63, ..., 45, 58, 58],\n",
              "       [83, 72, 54, ..., 59, 49,  1],\n",
              "       [83, 62, 47, ..., 46, 50, 51],\n",
              "       ...,\n",
              "       [83, 50, 58, ..., 63, 73, 76],\n",
              "       [83, 58, 64, ..., 53, 57,  1],\n",
              "       [83, 60, 50, ..., 62, 68, 45]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "next(generate_chunk())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfFRhsuDPkDM"
      },
      "source": [
        "Далее вам предстоит написать код для обучения модели и генерации текста."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNmki0O2PkDM",
        "outputId": "fd71e9c4-d444-4f8e-9659-8427e9af9753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Loss: 4.4697\n",
            "Epoch 2/30, Loss: 4.1686\n",
            "Epoch 3/30, Loss: 3.8559\n",
            "Epoch 4/30, Loss: 3.4502\n",
            "Epoch 5/30, Loss: 3.2818\n",
            "Epoch 6/30, Loss: 3.1214\n",
            "Epoch 7/30, Loss: 3.0721\n",
            "Epoch 8/30, Loss: 3.0212\n",
            "Epoch 9/30, Loss: 2.9867\n",
            "Epoch 10/30, Loss: 2.9034\n",
            "Epoch 11/30, Loss: 2.8683\n",
            "Epoch 12/30, Loss: 2.8306\n",
            "Epoch 13/30, Loss: 2.8019\n",
            "Epoch 14/30, Loss: 2.7780\n",
            "Epoch 15/30, Loss: 2.7879\n",
            "Epoch 16/30, Loss: 2.7559\n",
            "Epoch 17/30, Loss: 2.7096\n",
            "Epoch 18/30, Loss: 2.6810\n",
            "Epoch 19/30, Loss: 2.6727\n",
            "Epoch 20/30, Loss: 2.6484\n",
            "Epoch 21/30, Loss: 2.6505\n",
            "Epoch 22/30, Loss: 2.5979\n",
            "Epoch 23/30, Loss: 2.6353\n",
            "Epoch 24/30, Loss: 2.5931\n",
            "Epoch 25/30, Loss: 2.5826\n",
            "Epoch 26/30, Loss: 2.5588\n",
            "Epoch 27/30, Loss: 2.5513\n",
            "Epoch 28/30, Loss: 2.5449\n",
            "Epoch 29/30, Loss: 2.5564\n",
            "Epoch 30/30, Loss: 2.5285\n",
            "мой дядя самых честных правила тан жоной,\n",
            "но не\n",
            "пра; ноймиле вомочо шуго, де сели боол я с оно ведной рум причит,\n",
            "искиз яной презами врgзаяный\n",
            "одат пой ладарный прала ужа погобильюи номно ночиза дасли ожеть ой вим потья в оот про\n"
          ]
        }
      ],
      "source": [
        "class VanillaRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(VanillaRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        embedded = self.embedding(x)\n",
        "        out, hidden = self.rnn(embedded, hidden)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out, hidden\n",
        "\n",
        "def sample_with_temperature(logits, temperature=1.0):\n",
        "    probs = F.softmax(logits / temperature, dim=-1)\n",
        "    return torch.multinomial(probs, 1)\n",
        "\n",
        "def generate_text(model, start_string, length=100, temperature=1.0):\n",
        "    model.eval()\n",
        "    input_seq = torch.tensor([token_to_idx['<sos>']] + [token_to_idx[ch] for ch in start_string],\n",
        "                             dtype=torch.long).unsqueeze(0).to(device)\n",
        "    hidden = None\n",
        "    generated = start_string\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(length):\n",
        "            output, hidden = model(input_seq, hidden)\n",
        "            next_char_idx = sample_with_temperature(output[:, -1, :], temperature).item()\n",
        "            next_char = idx_to_token[next_char_idx]\n",
        "            generated += next_char\n",
        "            input_seq = torch.tensor([[next_char_idx]], dtype=torch.long).to(device)\n",
        "\n",
        "    return generated\n",
        "\n",
        "embedding_dim = 256\n",
        "hidden_dim = 512\n",
        "num_epochs = 30\n",
        "\n",
        "model = VanillaRNN(num_tokens, embedding_dim, hidden_dim).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch in generate_chunk():\n",
        "        batch = torch.tensor(batch, dtype=torch.long).to(device)\n",
        "        inputs, targets = batch[:, :-1], batch[:, 1:]\n",
        "        hidden = None\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs, hidden = model(inputs, hidden)\n",
        "\n",
        "        loss = criterion(outputs.reshape(-1, num_tokens), targets.reshape(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "start_string = \"мой дядя самых честных правил\"\n",
        "temperature = 0.8\n",
        "generated_text = generate_text(model, start_string, length=200, temperature=temperature)\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYkkB9ZFPkDM"
      },
      "source": [
        "В качестве иллюстрации ниже доступен график значений функции потерь, построенный в ходе обучения авторской сети (сам код для ее обучения вам и предстоит написать)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwpFh3GDPkDM",
        "outputId": "83d5f58c-694e-4c83-9ca4-8783d5d5eff1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSMKS26WPkDN"
      },
      "source": [
        "Шаблон функции `generate_sample` также доступен ниже. Вы можете как дозаполнить его, так и написать свою собственную функцию с нуля. Не забывайте, что все примеры в обучающей выборке начинались с токена `<sos>`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7PjQAEpPkDN"
      },
      "outputs": [],
      "source": [
        "def generate_sample(char_rnn, seed_phrase=None, max_length=200, temperature=1.0, device=device):\n",
        "    '''\n",
        "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
        "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
        "    :param max_length: maximum output length, including seed_phrase\n",
        "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
        "                        smaller temperature converges to the single most likely output\n",
        "    '''\n",
        "\n",
        "    if seed_phrase is not None:\n",
        "        x_sequence = [token_to_idx['<sos>']] + [token_to_idx[token] for token in seed_phrase]\n",
        "    else:\n",
        "        x_sequence = [token_to_idx['<sos>']]\n",
        "\n",
        "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64).to(device)\n",
        "\n",
        "    hidden = None\n",
        "    generated_text = seed_phrase if seed_phrase else ''\n",
        "\n",
        "    for _ in range(max_length - len(generated_text)):\n",
        "      output, hidden = char_rnn(x_sequence, hidden)\n",
        "\n",
        "      logits = output[:, -1, :]\n",
        "\n",
        "      next_char_idx = sample_with_temperature(logits, temperature).item()\n",
        "      next_char = idx_to_token[next_char_idx]\n",
        "\n",
        "      generated_text += next_char\n",
        "\n",
        "      x_sequence = torch.tensor([[next_char_idx]], dtype=torch.int64).to(device)\n",
        "\n",
        "    return generated_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cnknmj2jPkDN"
      },
      "source": [
        "Пример текста сгенерированного обученной моделью доступен ниже. Не страшно, что в тексте много несуществующих слов. Используемая модель очень проста: это простая классическая RNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipI2v84XPkDN",
        "outputId": "72e4dc6c-0f37-4ccd-b40a-7e3f61dbcae5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " мой дядя самых честных правиледо мом ной неч.\n",
            "\n",
            "\n",
            "вавси таят\n",
            "и ствней,\n",
            "вомою пони у скавста.\n",
            "\n",
            "\n",
            "xviii\n",
            "\n",
            "\n",
            "бе друтит,\n",
            "ины,\n",
            "я мета ведать исотомый\n",
            "воть васкол,\n",
            "глегоже дель неть бася нетим жазны презно ный воты мочне пренно выдали совецде, волени уматья\n",
            "\n",
            "xxxi[ здой мну\n",
            "и де точанико мона, толоные м бого не тевла молан,\n",
            "таль нолатраво, мечный,\n",
            "к бузьы вони томорне трали\n",
            " него та веет поленной чна пелонепесьяся онна нася,\n",
            "и плыня с калу!т,лено боста! трочусьены я игедне т радель лола стову,\n",
            "т зазлали со\n"
          ]
        }
      ],
      "source": [
        "print(generate_sample(model, ' мой дядя самых честных правил', max_length=500, temperature=0.8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rqKRxsQPkDN"
      },
      "source": [
        "### Сдача задания\n",
        "Сгенерируйте десять последовательностей длиной 500, используя строку ' мой дядя самых честных правил'. Температуру для генерации выберите самостоятельно на основании визуального качества генериуремого текста. Не забудьте удалить все технические токены в случае их наличия.\n",
        "\n",
        "Сгенерированную последовательность сохрание в переменную `generated_phrase` и сдайте сгенерированный ниже файл в контест."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wq1W9pKIPkDN"
      },
      "outputs": [],
      "source": [
        "seed_phrase = ' мой дядя самых честных правил'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s65H89HRPkDO"
      },
      "outputs": [],
      "source": [
        "generated_phrases = [\n",
        "    generate_sample(\n",
        "        model,\n",
        "        seed_phrase,\n",
        "        max_length=500,\n",
        "        temperature=0.8\n",
        "    ).replace('<sos>', '')\n",
        "    for _ in range(10)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajabQCRiPkDO",
        "outputId": "0ddc3a90-e52d-4302-abb2-084924c1e8a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "import json\n",
        "if 'generated_phrases' not in locals():\n",
        "    raise ValueError(\"Please, save generated phrases to `generated_phrases` variable\")\n",
        "\n",
        "for phrase in generated_phrases:\n",
        "\n",
        "    if not isinstance(phrase, str):\n",
        "        raise ValueError(\"The generated phrase should be a string\")\n",
        "\n",
        "    if len(phrase) != 500:\n",
        "        raise ValueError(\"The `generated_phrase` length should be equal to 500\")\n",
        "\n",
        "    assert all([x in set(tokens) for x in set(list(phrase))]), 'Unknown tokens detected, check your submission!'\n",
        "\n",
        "\n",
        "submission_dict = {\n",
        "    'token_to_idx': token_to_idx,\n",
        "    'generated_phrases': generated_phrases\n",
        "}\n",
        "\n",
        "with open('submission_dict.json', 'w') as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print('File saved to `submission_dict.json`')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZQof53RPkDO"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Улучшенные гиперпараметры\n",
        "embedding_dim = 512\n",
        "hidden_dim = 1024\n",
        "num_epochs = 50\n",
        "\n",
        "model = VanillaRNN(num_tokens, embedding_dim, hidden_dim).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch in generate_chunk():\n",
        "        batch = torch.tensor(batch, dtype=torch.long).to(device)\n",
        "        inputs, targets = batch[:, :-1], batch[:, 1:]\n",
        "        hidden = None\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs, hidden = model(inputs, hidden)\n",
        "        loss = criterion(outputs.reshape(-1, num_tokens), targets.reshape(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "# Генерация 10 последовательностей\n",
        "seed_phrase = ' мой дядя самых честных правил'\n",
        "temperature = 1.\n",
        "generated_phrases = [\n",
        "    generate_sample(model, seed_phrase, max_length=500, temperature=temperature).replace('<sos>', '')\n",
        "    for _ in range(10)\n",
        "]\n",
        "\n",
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "import json\n",
        "if 'generated_phrases' not in locals():\n",
        "    raise ValueError(\"Please, save generated phrases to `generated_phrases` variable\")\n",
        "\n",
        "for phrase in generated_phrases:\n",
        "\n",
        "    if not isinstance(phrase, str):\n",
        "        raise ValueError(\"The generated phrase should be a string\")\n",
        "\n",
        "    if len(phrase) != 500:\n",
        "        raise ValueError(\"The `generated_phrase` length should be equal to 500\")\n",
        "\n",
        "    assert all([x in set(tokens) for x in set(list(phrase))]), 'Unknown tokens detected, check your submission!'\n",
        "\n",
        "\n",
        "submission_dict = {\n",
        "    'token_to_idx': token_to_idx,\n",
        "    'generated_phrases': generated_phrases\n",
        "}\n",
        "\n",
        "with open('submission_dict.json', 'w') as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print('File saved to `submission_dict.json`')\n",
        "# __________end of block__________\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb3JBiinatvz",
        "outputId": "42b14737-7ae6-40e1-8024-acb7a51f2686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 4.4803\n",
            "Epoch 2/50, Loss: 3.7711\n",
            "Epoch 3/50, Loss: 3.1557\n",
            "Epoch 4/50, Loss: 3.0955\n",
            "Epoch 5/50, Loss: 2.9120\n",
            "Epoch 6/50, Loss: 2.8293\n",
            "Epoch 7/50, Loss: 2.7734\n",
            "Epoch 8/50, Loss: 2.7032\n",
            "Epoch 9/50, Loss: 2.6708\n",
            "Epoch 10/50, Loss: 2.6448\n",
            "Epoch 11/50, Loss: 2.6296\n",
            "Epoch 12/50, Loss: 2.6335\n",
            "Epoch 13/50, Loss: 2.5643\n",
            "Epoch 14/50, Loss: 2.5244\n",
            "Epoch 15/50, Loss: 2.5300\n",
            "Epoch 16/50, Loss: 2.5470\n",
            "Epoch 17/50, Loss: 2.5108\n",
            "Epoch 18/50, Loss: 2.4638\n",
            "Epoch 19/50, Loss: 2.4441\n",
            "Epoch 20/50, Loss: 2.4772\n",
            "Epoch 21/50, Loss: 2.4649\n",
            "Epoch 22/50, Loss: 2.4827\n",
            "Epoch 23/50, Loss: 2.4636\n",
            "Epoch 24/50, Loss: 2.4458\n",
            "Epoch 25/50, Loss: 2.4439\n",
            "Epoch 26/50, Loss: 2.3792\n",
            "Epoch 27/50, Loss: 2.4171\n",
            "Epoch 28/50, Loss: 2.3990\n",
            "Epoch 29/50, Loss: 2.3797\n",
            "Epoch 30/50, Loss: 2.3498\n",
            "Epoch 31/50, Loss: 2.3677\n",
            "Epoch 32/50, Loss: 2.3759\n",
            "Epoch 33/50, Loss: 2.3740\n",
            "Epoch 34/50, Loss: 2.3151\n",
            "Epoch 35/50, Loss: 2.3485\n",
            "Epoch 36/50, Loss: 2.3579\n",
            "Epoch 37/50, Loss: 2.3378\n",
            "Epoch 38/50, Loss: 2.3283\n",
            "Epoch 39/50, Loss: 2.3226\n",
            "Epoch 40/50, Loss: 2.2925\n",
            "Epoch 41/50, Loss: 2.3049\n",
            "Epoch 42/50, Loss: 2.2788\n",
            "Epoch 43/50, Loss: 2.3134\n",
            "Epoch 44/50, Loss: 2.2633\n",
            "Epoch 45/50, Loss: 2.2726\n",
            "Epoch 46/50, Loss: 2.2884\n",
            "Epoch 47/50, Loss: 2.2853\n",
            "Epoch 48/50, Loss: 2.2453\n",
            "Epoch 49/50, Loss: 2.2408\n",
            "Epoch 50/50, Loss: 2.2530\n",
            "File saved to `submission_dict.json`\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Py3 Research",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
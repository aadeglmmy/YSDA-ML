{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "recorded-outside",
   "metadata": {},
   "source": [
    "# Машинное обучение, ШАД, Минск\n",
    "## Лабораторная работа 3. Линейные модели классификации и регрессии, валидация моделей.\n",
    "\n",
    "\n",
    "**Правила:**\n",
    "\n",
    "* Выполненную работу нужно отправить в соответствующее задание в личном кабинете\n",
    "* Дедлайн **14 октября 23:59**. После дедлайна работы не принимаются кроме случаев наличия уважительной причины.\n",
    "* Для сдачи задания нужно загрузить **ноутбук в формате `ipynb`** в ЛМС.\n",
    "* Выполнять задание необходимо полностью самостоятельно.\n",
    "* Для выполнения задания используйте этот ноутбук в качестве основы, ничего не удаляя из него. Можно добавлять необходимое количество ячеек.\n",
    "* Комментарии к решению пишите в markdown-ячейках.\n",
    "* Выполнение задания (ход решения, выводы и пр.) должно быть осуществлено на русском языке.\n",
    "* Присылайте понятный и читаемый код. Если код не будет понятен проверяющему, оценка может быть снижена.\n",
    "* Код из данного задания при проверке запускаться не будет. *Если код студента не выполнен, недописан и т.д., то он не оценивается.*\n",
    "\n",
    "\n",
    "**Правила оформления теоретических задач:**\n",
    "\n",
    "* Решения необходимо прислать одним из следующих способов:\n",
    "  * фотографией в правильной ориентации, где все четко видно, а почерк разборчив,\n",
    "    * прикрепив ее в ЛМС в форматах `pdf`, `png` или `jpg` *или*\n",
    "    * вставив ее в ноутбук посредством `Edit -> Insert Image`;\n",
    "  * в виде $\\LaTeX$ в markdown-ячейках или в отдельном `pdf`-файле.\n",
    "* Решения не проверяются, если какое-то требование не выполнено. Особенно внимательно все проверьте в случае выбора второго пункта (вставки фото в ноутбук). <font color=\"red\"><b>Неправильно вставленные фотографии могут не передаться при отправке.</b></font> Для проверки попробуйте переместить `ipynb` в другую папку и открыть его там.\n",
    "* В решениях поясняйте, чем вы пользуетесь, хотя бы кратко. Например, если пользуетесь независимостью, то достаточно подписи вида \"*X и Y незав.*\"\n",
    "* Решение, в котором есть только ответ, и отсутствуют вычисления, оценивается в 0 баллов.\n",
    "\n",
    "**Максимальное количество баллов за задание: 5 баллов.**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-gnome",
   "metadata": {},
   "source": [
    "### Задание.\n",
    "\n",
    "Реализуйте логистическую регрессию с $L_2$ регуляризацией для поиска оценки параметров с помощью стохастического mini-batch градиентного спуска (SGD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "interested-backup",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d4xxxebKnQLm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "\n",
    "\n",
    "class LogisticRegression():\n",
    "    '''\n",
    "    Модель логистической регрессии. Имеет следующие гиперпараметры:\n",
    "\n",
    "    :param alpha: параметр регуляризации. \n",
    "                  Если равно 0, то регуляризация не происходит.\n",
    "    :param lr: константа, на которую домножаем градиент при обучении\n",
    "    :param max_iter: ограничение на кол-во итераций\n",
    "    :param fit_intercept: указывает, следует ли добавить константу в признаки\n",
    "    '''\n",
    "\n",
    "    def __init__(self, alpha=0, lr=0.5, max_iter=1e5,\n",
    "                 fit_intercept=True):\n",
    "        '''Создает модель и инициализирует параметры.'''\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.lr = lr\n",
    "        self.max_iter = max_iter\n",
    "        self.fit_intercept = fit_intercept\n",
    "\n",
    "    @staticmethod\n",
    "    def _sigmoid(x):\n",
    "        # используйте scipy.special.expit\n",
    "        return expit(x)\n",
    "\n",
    "    def _add_intercept(self, X):\n",
    "        '''\n",
    "        Добавляем свободный коэффициент к нашей модели. \n",
    "        Это происходит путем добавления вектора из 1 к исходной матрице.\n",
    "\n",
    "        :param X: исходная матрица признаков\n",
    "        :return: матрица X с добавленным свободным коэффициентов\n",
    "        '''\n",
    "\n",
    "        X_copy = np.full((X.shape[0], X.shape[1] + 1), fill_value=1.)\n",
    "        X_copy[:, :-1] = X\n",
    "\n",
    "        return X_copy\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        '''\n",
    "        Обучает модель логистической регресии с помощью SGD,\n",
    "        пока не выполнится self.max_iter итераций.\n",
    "\n",
    "        :param X: матрица признаков\n",
    "        :param Y: истинные метки\n",
    "        '''\n",
    "\n",
    "        assert X.shape[0] == Y.shape[0]\n",
    "\n",
    "        if self.fit_intercept:  # добавляем свободный коэфициент\n",
    "            X_copy = self._add_intercept(X)\n",
    "        else:\n",
    "            X_copy = X.copy()\n",
    "\n",
    "        n_samples, n_features = X_copy.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "\n",
    "        self.batch_size = 32\n",
    "\n",
    "        for _ in range(int(self.max_iter)):\n",
    "            indices = np.random.permutation(n_samples)\n",
    "            for i in range(0, n_samples, self.batch_size):\n",
    "                batch_indices = indices[i:i + self.batch_size]\n",
    "                X_batch = X_copy[batch_indices]\n",
    "                Y_batch = Y[batch_indices]\n",
    "\n",
    "                logit = np.dot(X_batch, self.weights)\n",
    "                y_pred = self._sigmoid(logit)\n",
    "\n",
    "                grad = -1 * np.dot(X_batch.T, Y_batch - y_pred)\n",
    "                if self.fit_intercept:\n",
    "                    regul = 2 * self.alpha * self.weights[:-1]\n",
    "                else:\n",
    "                    regul = 2 * self.alpha * self.weights\n",
    "\n",
    "                self.weights -= self.lr * grad\n",
    "                if self.fit_intercept:\n",
    "                    self.weights[:-1] -= self.lr * regul\n",
    "                else:\n",
    "                    self.weights -= self.lr * regul\n",
    "\n",
    "        self.coef_ = self.weights[:-1] if self.fit_intercept else self.weights # коэффициенты модели\n",
    "        self.intercept_ = self.weights[-1] if self.fit_intercept else 0  # свободный коэффициент\n",
    "        # self.weights состоит из коэффициентов модели и свободного члена\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Применяет обученную модель к данным \n",
    "        и возвращает точечное предсказание (оценку класса).\n",
    "\n",
    "        :param X: матрица признаков\n",
    "        :return: предсказание с размерностью (n_test, )\n",
    "        '''\n",
    "\n",
    "        if self.fit_intercept:\n",
    "            X_copy = self._add_intercept(X)\n",
    "        else:\n",
    "            X_copy = X.copy()\n",
    "\n",
    "        assert X_copy.shape[1] == self.weights.shape[0]\n",
    "\n",
    "        predictions = self._sigmoid(np.dot(X_copy, self.weights)) >= 0.5\n",
    "\n",
    "        return predictions.astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        '''\n",
    "        Применяет обученную модель к данным\n",
    "        и возвращает предсказание вероятности классов 0 и 1.\n",
    "\n",
    "        :param X: матрица признаков\n",
    "        :return: вероятности предсказания с размерностью (n_test, 2)\n",
    "        '''\n",
    "\n",
    "        if self.fit_intercept:\n",
    "            X_copy = self._add_intercept(X)\n",
    "        else:\n",
    "            X_copy = X.copy()\n",
    "\n",
    "        assert X_copy.shape[1] == self.weights.shape[0]\n",
    "\n",
    "        prob_predictions = self._sigmoid(np.dot(X_copy, self.weights))\n",
    "\n",
    "        return np.column_stack([1 - prob_predictions, prob_predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-adrian",
   "metadata": {},
   "source": [
    "Рассмотрим игрушечный датасет на $30$ признаков `load_breast_cancer` из библиотеки `sklearn`. Это относительно простой для бинарной классификации датасет по диагностике рака молочной железы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-request",
   "metadata": {
    "colab_type": "text",
    "id": "HHPTpzcWhv_W"
   },
   "source": [
    "Ради интереса можно прочитать описание признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "anonymous-raising",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "uUMbGPj-Fgfi",
    "outputId": "9b6b8f4b-d90a-42d7-d6d7-880c5853a33c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':Attribute Information:',\n",
       " '    - radius (mean of distances from center to points on the perimeter)',\n",
       " '    - texture (standard deviation of gray-scale values)',\n",
       " '    - perimeter',\n",
       " '    - area',\n",
       " '    - smoothness (local variation in radius lengths)',\n",
       " '    - compactness (perimeter^2 / area - 1.0)',\n",
       " '    - concavity (severity of concave portions of the contour)',\n",
       " '    - concave points (number of concave portions of the contour)',\n",
       " '    - symmetry',\n",
       " '    - fractal dimension (\"coastline approximation\" - 1)',\n",
       " '',\n",
       " '    The mean, standard error, and \"worst\" or largest (mean of the three',\n",
       " '    worst/largest values) of these features were computed for each image,',\n",
       " '    resulting in 30 features.  For instance, field 0 is Mean Radius, field',\n",
       " '    10 is Radius SE, field 20 is Worst Radius.',\n",
       " '',\n",
       " '    - class:',\n",
       " '            - WDBC-Malignant',\n",
       " '            - WDBC-Benign']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "dataset['DESCR'].split('\\n')[11:31]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-intersection",
   "metadata": {
    "colab_type": "text",
    "id": "JgaXPncW-Gab"
   },
   "source": [
    "Разделим нашу выборку на обучающую и тестовую:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "otherwise-savage",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WEn6HImRc8zJ",
    "outputId": "9c25a5a2-4ea6-4e33-c9be-b780470fbbbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 30), (114, 30), (455,), (114,))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X, Y = dataset['data'], dataset['target']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-process",
   "metadata": {
    "colab_type": "text",
    "id": "l8jzwZUCPB_l"
   },
   "source": [
    "При использовании регуляризации данные необходимо нормализовать. Воспользуемся для этого классом `StandardScaler` из библиотеки `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "backed-substance",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oNAqhHbZPBvb"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-break",
   "metadata": {},
   "source": [
    "Теперь обучите модель логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "armed-trinidad",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6yZEZS1tnv1q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9386\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, Y_train)\n",
    "\n",
    "Y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-guidance",
   "metadata": {},
   "source": [
    "На занятии обсуждали, что в нашей постановке задачи при сравнении выиграет модель с меньшим FN, ведь каждая не обнаруженная опухоль может стоить человеческой жизни. Чем меньше ложно отрицательных срабатываний, тем выше Recall модели, а значит разумно взять Recall в качестве целевой метрики. \n",
    "\n",
    "Построить модель с Recall = 1 довольно просто (Как?), но в ней не будет большого смысла, т.к., например, для нашей задачи отправление на доп. обследование может стоить дополнительных средств и времени специалистов, поэтому хотелось, чтобы наша модель имела неплохую точность. Какую метрику можно использовать, чтобы учесть и точность, и полноту?\n",
    "\n",
    "Чтобы учитывать и точность (precision), и полноту (recall), можно использовать F1-score — это гармоническое среднее между ними.\n",
    "\n",
    "$F_1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$\n",
    "\n",
    "Выберите и посчитайте целевые метрики для нашей задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "sweet-excerpt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.9155\n",
      "F1-score: 0.9489\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, f1_score\n",
    "\n",
    "\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-palestinian",
   "metadata": {
    "colab_type": "text",
    "id": "mE0rZ7vPCH_S"
   },
   "source": [
    "Рассмотрите как влияет размер шага (`learning rate`) на качество модели. Обучите каждую модель одинаковое число итераций (например, 10000), а затем посчитайте качество. Сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "automotive-partner",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UL0NzUTDbuxW"
   },
   "outputs": [],
   "source": [
    "lrs = [1e-5, 1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.3, 0.5, 0.7, 1, 2, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cooked-spring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-05, Recall: 0.9859, F1-score: 0.9859\n",
      "Learning rate: 0.0001, Recall: 0.9718, F1-score: 0.9787\n",
      "Learning rate: 0.001, Recall: 0.9155, F1-score: 0.9489\n",
      "Learning rate: 0.01, Recall: 0.9155, F1-score: 0.9489\n",
      "Learning rate: 0.1, Recall: 0.9155, F1-score: 0.9489\n",
      "Learning rate: 0.2, Recall: 0.9155, F1-score: 0.9489\n",
      "Learning rate: 0.3, Recall: 0.9155, F1-score: 0.9489\n",
      "Learning rate: 0.5, Recall: 0.9155, F1-score: 0.9489\n",
      "Learning rate: 0.7, Recall: 0.9155, F1-score: 0.9489\n",
      "Learning rate: 1, Recall: 0.9155, F1-score: 0.9489\n",
      "Learning rate: 2, Recall: 0.9155, F1-score: 0.9489\n",
      "Learning rate: 5, Recall: 0.9155, F1-score: 0.9489\n",
      "Learning rate: 10, Recall: 0.9155, F1-score: 0.9489\n"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = LogisticRegression(lr=lr)\n",
    "    model.fit(X_train_scaled, Y_train)\n",
    "\n",
    "    Y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    recall = recall_score(Y_test, Y_pred)\n",
    "    f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "    print(f'Learning rate: {lr}, Recall: {recall:.4f}, F1-score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-madness",
   "metadata": {
    "colab_type": "text",
    "id": "UQy0zIrcClfm"
   },
   "source": [
    "Рассмотрите несколько моделей, в которых установите не менее 5-ти различных коэффициентов регуляризации, а также модель без регуляризатора. Сравните, влияет ли наличие регуляризации на качество, сделайте выводы. Под качеством подразумевается значение какой-либо выбранной вами метрики качества классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "convertible-edmonton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0, Recall: 0.9155, F1-score: 0.9489\n",
      "Alpha: 1e-05, Recall: 0.9155, F1-score: 0.9489\n",
      "Alpha: 0.0001, Recall: 0.9014, F1-score: 0.9412\n",
      "Alpha: 0.001, Recall: 0.9577, F1-score: 0.9645\n",
      "Alpha: 0.01, Recall: 0.9577, F1-score: 0.9645\n",
      "Alpha: 0.1, Recall: 0.9718, F1-score: 0.9650\n",
      "Alpha: 0.2, Recall: 0.9859, F1-score: 0.9722\n",
      "Alpha: 0.3, Recall: 0.9718, F1-score: 0.9583\n",
      "Alpha: 0.5, Recall: 0.9859, F1-score: 0.9655\n",
      "Alpha: 0.7, Recall: 0.7606, F1-score: 0.8438\n",
      "Alpha: 1, Recall: 1.0000, F1-score: 0.7676\n",
      "Alpha: 2, Recall: 0.0423, F1-score: 0.0522\n"
     ]
    }
   ],
   "source": [
    "alphas = [0, 1e-5, 1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.3, 0.5, 0.7, 1, 2]\n",
    "\n",
    "for alpha in alphas:\n",
    "    model = LogisticRegression(alpha=alpha)\n",
    "    model.fit(X_train_scaled, Y_train)\n",
    "\n",
    "    Y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    recall = recall_score(Y_test, Y_pred)\n",
    "    f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "    print(f'Alpha: {alpha}, Recall: {recall:.4f}, F1-score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-expense",
   "metadata": {},
   "source": [
    "Выберите наилучшее значение коэффициента регуляризации с помощью кросс-валидации для двух подходов &mdash; `KFold` и `ShuffleSplit`. Используйте пять фолдов/разбиений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "assisted-rouge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold results (sorted by F1-score):\n",
      "Alpha: 0.001, F1-score: 0.9689\n",
      "Alpha: 0.01, F1-score: 0.9649\n",
      "Alpha: 0, F1-score: 0.9642\n",
      "Alpha: 1e-05, F1-score: 0.9642\n",
      "Alpha: 0.0001, F1-score: 0.9629\n",
      "Alpha: 0.1, F1-score: 0.9599\n",
      "Alpha: 0.2, F1-score: 0.9466\n",
      "Alpha: 0.3, F1-score: 0.9336\n",
      "Alpha: 0.5, F1-score: 0.9185\n",
      "Alpha: 0.7, F1-score: 0.8997\n",
      "Alpha: 1, F1-score: 0.8959\n",
      "Alpha: 2, F1-score: 0.1032\n",
      "ShuffleSplit results (sorted by F1-score):\n",
      "Alpha: 0.001, F1_score: 0.9800\n",
      "Alpha: 0.01, F1_score: 0.9800\n",
      "Alpha: 0.0001, F1_score: 0.9797\n",
      "Alpha: 0, F1_score: 0.9768\n",
      "Alpha: 1e-05, F1_score: 0.9768\n",
      "Alpha: 0.1, F1_score: 0.9579\n",
      "Alpha: 0.5, F1_score: 0.9425\n",
      "Alpha: 0.2, F1_score: 0.9280\n",
      "Alpha: 0.3, F1_score: 0.9213\n",
      "Alpha: 0.7, F1_score: 0.8781\n",
      "Alpha: 1, F1_score: 0.8086\n",
      "Alpha: 2, F1_score: 0.0995\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, ShuffleSplit\n",
    "\n",
    "\n",
    "def cross_val_logistic_regression(X, Y, alphas, cv):\n",
    "    results = []\n",
    "\n",
    "    for alpha in alphas:\n",
    "        scores = []\n",
    "\n",
    "        for train_idx, test_idx in cv.split(X):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            Y_train, Y_test = Y[train_idx], Y[test_idx]\n",
    "\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            model = LogisticRegression(alpha=alpha)\n",
    "            model.fit(X_train_scaled, Y_train)\n",
    "            Y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "            score = f1_score(Y_test, Y_pred)\n",
    "\n",
    "            scores.append(score)\n",
    "\n",
    "        mean_score = np.mean(scores)\n",
    "        results.append((alpha, mean_score))\n",
    "\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "kf_results = cross_val_logistic_regression(X, Y, alphas, cv=kf)\n",
    "print(\"KFold results (sorted by F1-score):\")\n",
    "for alpha, score in kf_results:\n",
    "    print(f'Alpha: {alpha}, F1-score: {score:.4f}')\n",
    "\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "ss_results = cross_val_logistic_regression(X, Y, alphas, cv=ss)\n",
    "print('ShuffleSplit results (sorted by F1-score):')\n",
    "for alpha, score in ss_results:\n",
    "    print(f'Alpha: {alpha}, F1_score: {score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365dfe74-d6e3-480e-a212-dbf0fbf93fe7",
   "metadata": {},
   "source": [
    "Для выбранного значения коэффициента регуляризации оцените дисперсию усредненного значения метрики качества на тестовых батчах. Для этого выполните кросс-валидацию достаточно много раз (не менее 100) и посчитайте выборочную дисперсию. Обратите внимание, что для стратегии `KFold` нужно на каждой итерации перемешивать данные, для этого можно указать `shuffle=True`.\n",
    "\n",
    "Сравните эти две стратегии кросс-валидации. Какие их преимущества и недостатки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e1a734-b563-4bea-bcc9-f295fc14e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_cross_val_logistic_regression(X, Y, alpha, cv, n_iter=100):\n",
    "    scores = []\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        iter_scores = []\n",
    "\n",
    "        for train_idx, test_idx in cv.split(X):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            Y_train, Y_test = Y[train_idx], Y[test_idx]\n",
    "\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            model = LogisticRegression(alpha=alpha)\n",
    "            model.fit(X_train_scaled, Y_train)\n",
    "            Y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "            score = f1_score(Y_test, Y_pred)\n",
    "            iter_scores.append(score)\n",
    "\n",
    "        mean_iter_score = np.mean(iter_scores)\n",
    "        scores.append(mean_iter_score)\n",
    "\n",
    "    return np.array(scores)\n",
    "\n",
    "alpha = 0.001\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "kf_scores = multiple_cross_val_logistic_regression(X, Y, alpha, cv=kf, n_iter=100)\n",
    "\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "ss_scores = multiple_cross_val_logistic_regression(X, Y, alpha, cv=ss, n_iter=100)\n",
    "\n",
    "kf_variance = np.var(kf_scores)\n",
    "ss_variance = np.var(ss_scores)\n",
    "\n",
    "print(f'Dispersion for KFold: {kf_variance:.6f}')\n",
    "print(f'Dispersion for ShuffleSplit: {ss_variance:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-syntax",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "\n",
    "1. **KFold с перемешиванием:**\n",
    "   - **Преимущества:** Каждая часть данных используется как для обучения, так и для тестирования, что делает оценку более точной. Перемешивание уменьшает возможное смещение данных.\n",
    "   - **Недостатки:** Вычислительно более затратен, особенно при большом количестве данных. Может привести к большему разбросу оценок на меньших тестовых наборах.\n",
    "\n",
    "2. **ShuffleSplit:**\n",
    "   - **Преимущества:** Гибкость в настройке размера тестовой выборки. Более быстрый и менее затратный метод. Более стабильные оценки, так как тестовые выборки больше.\n",
    "   - **Недостатки:** Некоторая выборка может не использоваться в обучении или тестировании. Возможны повторяющиеся выборки в разных разбиениях.\n",
    "\n",
    "**Заключение:** KFold обеспечивает более точную оценку за счет использования всех данных, но медленнее. ShuffleSplit более гибкий и быстрый, но может вносить смещение в оценку."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
